{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Analysing gpt-4o model vs finetuned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T18:01:49.746859Z",
     "start_time": "2025-09-15T18:01:49.639775Z"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mgeval import core, utils\n",
    "from sklearn.model_selection import LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_1 = \"gpt-4o\"\n",
    "MODEL_2 = \"finetuned\"\n",
    "\n",
    "SET_1_PATH = \"data/evaluation/midi/{}/*\".format(MODEL_1)\n",
    "SET_2_PATH = \"data/evaluation/midi/{}/*\".format(MODEL_2)\n",
    "\n",
    "SET_1_CALCULATED_METRICS_PATH = \"data/evaluation/results/{}_vs_{}/{}_calculated_metrics.pkl\".format(MODEL_1, MODEL_2, MODEL_1)\n",
    "SET_2_CALCULATED_METRICS_PATH = \"data/evaluation/results/{}_vs_{}/{}_calculated_metrics.pkl\".format(MODEL_1, MODEL_2, MODEL_2)\n",
    "\n",
    "ABSOLUTE_METRICS_STATISTICS_PATH = \"data/evaluation/results/{}_vs_{}/absolute_metrics_statistics.pkl\".format(MODEL_1, MODEL_2)\n",
    "RELATIVE_METRICS_STATISTICS_PATH = \"data/evaluation/results/{}_vs_{}/relative_metrics_statistics.pkl\".format(MODEL_1, MODEL_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Absolute measurement: statistic analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Assign sample dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T18:01:49.764589Z",
     "start_time": "2025-09-15T18:01:49.756759Z"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "set1 = glob.glob(SET_1_PATH)\n",
    "print(set1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T18:03:05.607690Z",
     "start_time": "2025-09-12T18:03:05.602126Z"
    }
   },
   "source": [
    "Assign baseline dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T18:01:49.819538Z",
     "start_time": "2025-09-15T18:01:49.811705Z"
    }
   },
   "outputs": [],
   "source": [
    "set2 = glob.glob(SET_2_PATH)\n",
    "print(set2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build empty dictionary to fill in measurement across samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T18:01:49.922639Z",
     "start_time": "2025-09-15T18:01:49.915280Z"
    }
   },
   "outputs": [],
   "source": [
    "num_samples = min(len(set2), len(set1))\n",
    "display(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_eval_dict(num_samples):\n",
    "    return {\n",
    "        # Pitch-based features\n",
    "        'total_used_pitch': np.zeros((num_samples, 1)),\n",
    "        'total_pitch_class_histogram': np.zeros((num_samples, 12)),\n",
    "        'pitch_class_transition_matrix': np.zeros((num_samples, 12, 12)),\n",
    "        'pitch_range': np.zeros((num_samples, 1)),\n",
    "        'avg_pitch_shift': np.zeros((num_samples, 1)),\n",
    "        # Rhythm-based features\n",
    "        'total_used_note': np.zeros((num_samples, 1)),\n",
    "        'avg_IOI': np.zeros((num_samples, 1)),\n",
    "        'note_length_hist': np.zeros((num_samples, 12)),\n",
    "        'note_length_transition_matrix': np.zeros((num_samples, 12, 12)),\n",
    "    }\n",
    "\n",
    "set1_eval = init_eval_dict(num_samples)\n",
    "set2_eval = init_eval_dict(num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of metrics to calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = set1_eval.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate absolute metrics\n",
    "\n",
    "First dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T18:01:55.852966Z",
     "start_time": "2025-09-15T18:01:49.968009Z"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, num_samples):\n",
    "    feature = core.extract_feature(set1[i])\n",
    "    for metric in metrics_list:\n",
    "        set1_eval[metric][i] = getattr(core.metrics(), metric)(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write set1_eval calculated metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SET_1_CALCULATED_METRICS_PATH, \"wb\") as f:\n",
    "    pickle.dump(set1_eval, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Second dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T18:02:03.949373Z",
     "start_time": "2025-09-15T18:01:55.931242Z"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, num_samples):\n",
    "    feature = core.extract_feature(set2[i])\n",
    "    for metric in metrics_list:\n",
    "        set2_eval[metric][i] = getattr(core.metrics(), metric)(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write set2_eval calculated metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SET_2_CALCULATED_METRICS_PATH, \"wb\") as f:\n",
    "    pickle.dump(set2_eval, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Statistic analysis: absolute measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_stats = {}\n",
    "for metric in metrics_list:\n",
    "    set1_mean = np.mean(set1_eval[metric], axis=0)\n",
    "    set1_std = np.std(set1_eval[metric], axis=0)\n",
    "    set2_mean = np.mean(set2_eval[metric], axis=0)\n",
    "    set2_std = np.std(set2_eval[metric], axis=0)\n",
    "    summary_stats[metric] = {\n",
    "        MODEL_1: {'mean': set1_mean.tolist(), 'std': set1_std.tolist()},\n",
    "        MODEL_2: {'mean': set2_mean.tolist(), 'std': set2_std.tolist()}\n",
    "    }\n",
    "\n",
    "    print('------------------------------------------------------------------------------------------------')\n",
    "    print('Metric: {}'.format(metric))\n",
    "    print('{} => Mean: {}, Std: {}'.format(MODEL_1, set1_mean, set1_std))\n",
    "    print('{} => Mean: {}, Std: {}'.format(MODEL_2, set2_mean, set2_std))\n",
    "    print('------------------------------------------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write absolute metrics statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ABSOLUTE_METRICS_STATISTICS_PATH, \"wb\") as f:\n",
    "    pickle.dump(summary_stats, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Relative measurement: generalizes the result among features with various dimensions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "the features are sum- marized to \n",
    "- the intra-set distances\n",
    "- the difference of intra-set and inter-set distances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "exhaustive cross-validation for intra-set distances measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T18:02:04.972366Z",
     "start_time": "2025-09-15T18:02:04.160122Z"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(np.arange(num_samples))\n",
    "set1_intra = np.zeros((num_samples, len(metrics_list), num_samples - 1))\n",
    "set2_intra = np.zeros((num_samples, len(metrics_list), num_samples - 1))\n",
    "for i in range(len(metrics_list)):\n",
    "    for train_index, test_index in loo.split(np.arange(num_samples)):\n",
    "        set1_intra[test_index[0]][i] = utils.c_dist(set1_eval[metrics_list[i]][test_index], set1_eval[metrics_list[i]][train_index])\n",
    "        set2_intra[test_index[0]][i] = utils.c_dist(set2_eval[metrics_list[i]][test_index], set2_eval[metrics_list[i]][train_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "exhaustive cross-validation for inter-set distances measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T18:02:05.492110Z",
     "start_time": "2025-09-15T18:02:05.049009Z"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(np.arange(num_samples))\n",
    "sets_inter = np.zeros((num_samples, len(metrics_list), num_samples))\n",
    "\n",
    "for i in range(len(metrics_list)):\n",
    "    for train_index, test_index in loo.split(np.arange(num_samples)):\n",
    "        sets_inter[test_index[0]][i] = utils.c_dist(set1_eval[metrics_list[i]][test_index], set2_eval[metrics_list[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "visualization of intra-set and inter-set distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T18:02:07.973479Z",
     "start_time": "2025-09-15T18:02:05.507474Z"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plot_set1_intra = np.transpose(set1_intra,(1, 0, 2)).reshape(len(metrics_list), -1)\n",
    "plot_set2_intra = np.transpose(set2_intra,(1, 0, 2)).reshape(len(metrics_list), -1)\n",
    "plot_sets_inter = np.transpose(sets_inter,(1, 0, 2)).reshape(len(metrics_list), -1)\n",
    "for i in range(0,len(metrics_list)):\n",
    "    sns.kdeplot(plot_set1_intra[i], label='intra_set1')\n",
    "    sns.kdeplot(plot_sets_inter[i], label='inter')\n",
    "    sns.kdeplot(plot_set2_intra[i], label='intra_set2')\n",
    "\n",
    "    plt.title(metrics_list[i])\n",
    "    plt.xlabel('Euclidean distance')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "the difference of intra-set and inter-set distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T18:02:21.355778Z",
     "start_time": "2025-09-15T18:02:08.083559Z"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "relative_stats = {}\n",
    "for i in range(0, len(metrics_list)):\n",
    "    kl1 = utils.kl_dist(plot_set1_intra[i], plot_sets_inter[i])\n",
    "    overlap1 = utils.overlap_area(plot_set1_intra[i], plot_sets_inter[i])\n",
    "    kl2 = utils.kl_dist(plot_set2_intra[i], plot_sets_inter[i])\n",
    "    overlap2 = utils.overlap_area(plot_set2_intra[i], plot_sets_inter[i])\n",
    "    metric = metrics_list[i]\n",
    "    relative_stats[metric] = {\n",
    "        MODEL_1: {\n",
    "            'kl_divergence': kl1,\n",
    "            'overlap_area': overlap1\n",
    "        },\n",
    "        MODEL_2: {\n",
    "            'kl_divergence': kl2,\n",
    "            'overlap_area': overlap2\n",
    "        }\n",
    "    }\n",
    "    print('------------------------------------------------------------------------------------------------')\n",
    "    print('Metric: {}'.format(metric))\n",
    "    print('{} => Kullback–Leibler divergence: {}, Overlap area: {}'.format(MODEL_1, kl1, overlap1))\n",
    "    print('{} => Kullback–Leibler divergence: {}, Overlap area: {}'.format(MODEL_2, kl2, overlap2))\n",
    "    print('------------------------------------------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write relative metrics statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T18:02:21.443204Z",
     "start_time": "2025-09-15T18:02:21.438183Z"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(RELATIVE_METRICS_STATISTICS_PATH, \"wb\") as f:\n",
    "    pickle.dump(relative_stats, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
